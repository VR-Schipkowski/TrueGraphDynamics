{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35b491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import temporal_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import temporal_graph_for_training\n",
    "\n",
    "\n",
    "import importlib\n",
    "import torch\n",
    "\n",
    "import temporal_graph_for_training\n",
    "importlib.reload(temporal_graph_for_training)\n",
    "\n",
    "from temporal_graph_for_training import TemporalGraph, TemporalTruthModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5b14b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating time intervall ...\n",
      "the time intervall of the data goes\n",
      "from: 2022-02-08 16:22:00 \n",
      "to: 2022-10-14 20:48:00\n",
      "we have the following time intervalls[(Timestamp('2022-02-08 16:22:00'), Timestamp('2022-02-15 16:22:00')), (Timestamp('2022-02-15 16:22:00'), Timestamp('2022-02-22 16:22:00')), (Timestamp('2022-02-22 16:22:00'), Timestamp('2022-03-01 16:22:00')), (Timestamp('2022-03-01 16:22:00'), Timestamp('2022-03-08 16:22:00')), (Timestamp('2022-03-08 16:22:00'), Timestamp('2022-03-15 16:22:00')), (Timestamp('2022-03-15 16:22:00'), Timestamp('2022-03-22 16:22:00')), (Timestamp('2022-03-22 16:22:00'), Timestamp('2022-03-29 16:22:00')), (Timestamp('2022-03-29 16:22:00'), Timestamp('2022-04-05 16:22:00')), (Timestamp('2022-04-05 16:22:00'), Timestamp('2022-04-12 16:22:00')), (Timestamp('2022-04-12 16:22:00'), Timestamp('2022-04-19 16:22:00')), (Timestamp('2022-04-19 16:22:00'), Timestamp('2022-04-26 16:22:00')), (Timestamp('2022-04-26 16:22:00'), Timestamp('2022-05-03 16:22:00')), (Timestamp('2022-05-03 16:22:00'), Timestamp('2022-05-10 16:22:00')), (Timestamp('2022-05-10 16:22:00'), Timestamp('2022-05-17 16:22:00')), (Timestamp('2022-05-17 16:22:00'), Timestamp('2022-05-24 16:22:00')), (Timestamp('2022-05-24 16:22:00'), Timestamp('2022-05-31 16:22:00')), (Timestamp('2022-05-31 16:22:00'), Timestamp('2022-06-07 16:22:00')), (Timestamp('2022-06-07 16:22:00'), Timestamp('2022-06-14 16:22:00')), (Timestamp('2022-06-14 16:22:00'), Timestamp('2022-06-21 16:22:00')), (Timestamp('2022-06-21 16:22:00'), Timestamp('2022-06-28 16:22:00')), (Timestamp('2022-06-28 16:22:00'), Timestamp('2022-07-05 16:22:00')), (Timestamp('2022-07-05 16:22:00'), Timestamp('2022-07-12 16:22:00')), (Timestamp('2022-07-12 16:22:00'), Timestamp('2022-07-19 16:22:00')), (Timestamp('2022-07-19 16:22:00'), Timestamp('2022-07-26 16:22:00')), (Timestamp('2022-07-26 16:22:00'), Timestamp('2022-08-02 16:22:00')), (Timestamp('2022-08-02 16:22:00'), Timestamp('2022-08-09 16:22:00')), (Timestamp('2022-08-09 16:22:00'), Timestamp('2022-08-16 16:22:00')), (Timestamp('2022-08-16 16:22:00'), Timestamp('2022-08-23 16:22:00')), (Timestamp('2022-08-23 16:22:00'), Timestamp('2022-08-30 16:22:00')), (Timestamp('2022-08-30 16:22:00'), Timestamp('2022-09-06 16:22:00')), (Timestamp('2022-09-06 16:22:00'), Timestamp('2022-09-13 16:22:00')), (Timestamp('2022-09-13 16:22:00'), Timestamp('2022-09-20 16:22:00')), (Timestamp('2022-09-20 16:22:00'), Timestamp('2022-09-27 16:22:00')), (Timestamp('2022-09-27 16:22:00'), Timestamp('2022-10-04 16:22:00')), (Timestamp('2022-10-04 16:22:00'), Timestamp('2022-10-11 16:22:00')), (Timestamp('2022-10-11 16:22:00'), Timestamp('2022-10-14 20:48:00'))]\n",
      "creating user nodes ...\n",
      "assigning comments to intervalls ...\n",
      "creating edges ...\n",
      "of 4002115 edges, 221804 edges are correct\n",
      "assigning truth flags ...\n"
     ]
    }
   ],
   "source": [
    "temporal_graph = temporal_graph_for_training.TemporalGraph()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2dfe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample authors from CSV: [2247, 20054, 11225, 11225, 11225, 11225, 11225, 11225, 11225, 11225]\n",
      "Type of first author: <class 'int'>\n",
      "Sample user node keys: ['2247', '20054', '11225', '2335', '15010', '20030', '14695', '20058', '18270', '17712']\n",
      "Type of key: <class 'str'>\n",
      "FOUND COMMENTS\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "# inspect raw author values\n",
    "authors = temporal_graph.comment_df[\"author\"].head(10).tolist()\n",
    "print(\"Sample authors from CSV:\", authors)\n",
    "print(\"Type of first author:\", type(authors[0]))\n",
    "\n",
    "# inspect user node keys\n",
    "keys = list(temporal_graph.user_nodes.keys())[:10]\n",
    "print(\"Sample user node keys:\", keys)\n",
    "print(\"Type of key:\", type(keys[0]))\n",
    "\n",
    "for u in temporal_graph.user_nodes.values():\n",
    "    if u.comments:\n",
    "        print(\"FOUND COMMENTS\")\n",
    "        print(len(u.comments))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3649918",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in temporal_graph.user_nodes.values():\n",
    "    \n",
    "    if u.comments:\n",
    "        c = next(iter(u.comments.values()))\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"No users with comments found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce86819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== SANITY CHECKS =====\n",
      "Number of users: 2251\n",
      "Number of time intervals: 36\n",
      "Comments per interval (first 10): [433, 2394, 4558, 5140, 5657, 4444, 4016, 3663, 3238, 2720]\n",
      "Total comments: 164705\n",
      "=========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"===== SANITY CHECKS =====\")\n",
    "print(\"Number of users:\", len(temporal_graph.user_nodes))\n",
    "print(\"Number of time intervals:\",\n",
    "      len(temporal_graph.time_intervall.time_intervalls))\n",
    "\n",
    "# count comments per interval (global)\n",
    "interval_counts = [\n",
    "    sum(len(u.comments_in_intervall[t])\n",
    "        for u in temporal_graph.user_nodes.values())\n",
    "    for t in range(len(temporal_graph.time_intervall.time_intervalls))\n",
    "]\n",
    "\n",
    "print(\"Comments per interval (first 10):\", interval_counts[:10])\n",
    "print(\"Total comments:\", sum(interval_counts))\n",
    "print(\"=========================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "COMMENT_DIM = 129\n",
      "Train: 0 → 27\n",
      "Val  : 35\n",
      "\n",
      "=== Trial 1 ===\n",
      "Threshold: 0.35, Use Past Y: False, Use Graph: False, Use Comments: True, Graph Type: sage\n",
      "Epoch 00 | Loss: 17.228 | Macro F1: 0.290| Acc: 0.317Prec1: 0.082|Rec1: 0.957|F1_1: 0.151|Prec0: 0.989|Rec0: 0.274|F1_0: 0.429\n",
      "Epoch 01 | Loss: 9.894 | Macro F1: 0.557| Acc: 0.716Prec1: 0.173|Rec1: 0.918|F1_1: 0.291|Prec0: 0.992|Rec0: 0.703|F1_0: 0.823\n",
      "Epoch 02 | Loss: 8.450 | Macro F1: 0.539| Acc: 0.684Prec1: 0.164|Rec1: 0.970|F1_1: 0.280|Prec0: 0.997|Rec0: 0.665|F1_0: 0.798\n",
      "Epoch 03 | Loss: 7.940 | Macro F1: 0.525| Acc: 0.662Prec1: 0.156|Rec1: 0.985|F1_1: 0.269|Prec0: 0.998|Rec0: 0.640|F1_0: 0.780\n",
      "Epoch 04 | Loss: 7.421 | Macro F1: 0.625| Acc: 0.797Prec1: 0.231|Rec1: 0.946|F1_1: 0.371|Prec0: 0.995|Rec0: 0.787|F1_0: 0.879\n",
      "Epoch 05 | Loss: 6.360 | Macro F1: 0.641| Acc: 0.819Prec1: 0.247|Rec1: 0.910|F1_1: 0.389|Prec0: 0.993|Rec0: 0.813|F1_0: 0.894\n",
      "Epoch 06 | Loss: 5.955 | Macro F1: 0.644| Acc: 0.819Prec1: 0.250|Rec1: 0.928|F1_1: 0.394|Prec0: 0.994|Rec0: 0.812|F1_0: 0.894\n",
      "Epoch 07 | Loss: 5.784 | Macro F1: 0.650| Acc: 0.825Prec1: 0.256|Rec1: 0.926|F1_1: 0.402|Prec0: 0.994|Rec0: 0.818|F1_0: 0.898\n",
      "Epoch 08 | Loss: 5.643 | Macro F1: 0.658| Acc: 0.835Prec1: 0.266|Rec1: 0.909|F1_1: 0.411|Prec0: 0.993|Rec0: 0.830|F1_0: 0.904\n",
      "Epoch 09 | Loss: 5.475 | Macro F1: 0.667| Acc: 0.847Prec1: 0.277|Rec1: 0.883|F1_1: 0.422|Prec0: 0.991|Rec0: 0.844|F1_0: 0.912\n",
      "Epoch 10 | Loss: 5.302 | Macro F1: 0.673| Acc: 0.856Prec1: 0.287|Rec1: 0.857|F1_1: 0.430|Prec0: 0.989|Rec0: 0.856|F1_0: 0.917\n",
      "Epoch 11 | Loss: 5.138 | Macro F1: 0.676| Acc: 0.859Prec1: 0.290|Rec1: 0.848|F1_1: 0.433|Prec0: 0.988|Rec0: 0.860|F1_0: 0.919\n",
      "Epoch 12 | Loss: 4.989 | Macro F1: 0.679| Acc: 0.861Prec1: 0.294|Rec1: 0.854|F1_1: 0.437|Prec0: 0.989|Rec0: 0.861|F1_0: 0.920\n",
      "Epoch 13 | Loss: 4.872 | Macro F1: 0.681| Acc: 0.862Prec1: 0.297|Rec1: 0.864|F1_1: 0.442|Prec0: 0.989|Rec0: 0.861|F1_0: 0.921\n",
      "Epoch 14 | Loss: 4.780 | Macro F1: 0.826| Acc: 0.948Prec1: 0.559|Rec1: 0.869|F1_1: 0.680|Prec0: 0.991|Rec0: 0.954|F1_0: 0.972\n",
      "Epoch 15 | Loss: 4.750 | Macro F1: 0.815| Acc: 0.942Prec1: 0.527|Rec1: 0.890|F1_1: 0.662|Prec0: 0.992|Rec0: 0.946|F1_0: 0.969\n",
      "Epoch 16 | Loss: 4.680 | Macro F1: 0.810| Acc: 0.939Prec1: 0.513|Rec1: 0.902|F1_1: 0.654|Prec0: 0.993|Rec0: 0.942|F1_0: 0.967\n",
      "Epoch 17 | Loss: 4.578 | Macro F1: 0.852| Acc: 0.962Prec1: 0.670|Rec1: 0.786|F1_1: 0.724|Prec0: 0.985|Rec0: 0.974|F1_0: 0.980\n",
      "Epoch 18 | Loss: 4.498 | Macro F1: 0.851| Acc: 0.966Prec1: 0.750|Rec1: 0.693|F1_1: 0.721|Prec0: 0.979|Rec0: 0.984|F1_0: 0.982\n",
      "Epoch 19 | Loss: 5.125 | Macro F1: 0.749| Acc: 0.901Prec1: 0.388|Rec1: 0.961|F1_1: 0.552|Prec0: 0.997|Rec0: 0.897|F1_0: 0.945\n",
      "Epoch 20 | Loss: 4.937 | Macro F1: 0.795| Acc: 0.931Prec1: 0.476|Rec1: 0.924|F1_1: 0.628|Prec0: 0.994|Rec0: 0.931|F1_0: 0.962\n",
      "Epoch 21 | Loss: 4.462 | Macro F1: 0.837| Acc: 0.953Prec1: 0.587|Rec1: 0.863|F1_1: 0.699|Prec0: 0.990|Rec0: 0.959|F1_0: 0.974\n",
      "Epoch 22 | Loss: 4.323 | Macro F1: 0.851| Acc: 0.959Prec1: 0.636|Rec1: 0.839|F1_1: 0.723|Prec0: 0.989|Rec0: 0.968|F1_0: 0.978\n",
      "Early stopping.\n",
      "Saved time-series plots to plots\\trial_1\n",
      "\n",
      "=== Trial 2 ===\n",
      "Threshold: 0.35, Use Past Y: False, Use Graph: True, Use Comments: True, Graph Type: sage\n",
      "Epoch 00 | Loss: 15.443 | Macro F1: 0.409| Acc: 0.611Prec1: 0.038|Rec1: 0.209|F1_1: 0.064|Prec0: 0.923|Rec0: 0.639|F1_0: 0.755\n",
      "Epoch 01 | Loss: 8.750 | Macro F1: 0.658| Acc: 0.846Prec1: 0.268|Rec1: 0.826|F1_1: 0.405|Prec0: 0.986|Rec0: 0.848|F1_0: 0.912\n",
      "Epoch 02 | Loss: 6.731 | Macro F1: 0.730| Acc: 0.905Prec1: 0.379|Rec1: 0.788|F1_1: 0.512|Prec0: 0.985|Rec0: 0.913|F1_0: 0.947\n",
      "Epoch 03 | Loss: 6.045 | Macro F1: 0.773| Acc: 0.928Prec1: 0.461|Rec1: 0.800|F1_1: 0.585|Prec0: 0.986|Rec0: 0.937|F1_0: 0.961\n",
      "Epoch 04 | Loss: 5.442 | Macro F1: 0.815| Acc: 0.954Prec1: 0.619|Rec1: 0.697|F1_1: 0.656|Prec0: 0.979|Rec0: 0.971|F1_0: 0.975\n",
      "Epoch 05 | Loss: 5.195 | Macro F1: 0.782| Acc: 0.928Prec1: 0.464|Rec1: 0.867|F1_1: 0.604|Prec0: 0.990|Rec0: 0.932|F1_0: 0.960\n",
      "Epoch 06 | Loss: 4.989 | Macro F1: 0.840| Acc: 0.961Prec1: 0.681|Rec1: 0.724|F1_1: 0.702|Prec0: 0.981|Rec0: 0.977|F1_0: 0.979\n",
      "Epoch 07 | Loss: 4.773 | Macro F1: 0.812| Acc: 0.943Prec1: 0.529|Rec1: 0.858|F1_1: 0.654|Prec0: 0.990|Rec0: 0.948|F1_0: 0.969\n",
      "Epoch 08 | Loss: 4.659 | Macro F1: 0.846| Acc: 0.965Prec1: 0.742|Rec1: 0.682|F1_1: 0.711|Prec0: 0.979|Rec0: 0.984|F1_0: 0.981\n",
      "Epoch 09 | Loss: 4.662 | Macro F1: 0.801| Acc: 0.936Prec1: 0.498|Rec1: 0.888|F1_1: 0.638|Prec0: 0.992|Rec0: 0.939|F1_0: 0.965\n",
      "Epoch 10 | Loss: 4.549 | Macro F1: 0.850| Acc: 0.965Prec1: 0.730|Rec1: 0.706|F1_1: 0.718|Prec0: 0.980|Rec0: 0.982|F1_0: 0.981\n",
      "Epoch 11 | Loss: 4.471 | Macro F1: 0.813| Acc: 0.942Prec1: 0.525|Rec1: 0.876|F1_1: 0.657|Prec0: 0.991|Rec0: 0.946|F1_0: 0.968\n",
      "Epoch 12 | Loss: 4.405 | Macro F1: 0.852| Acc: 0.965Prec1: 0.735|Rec1: 0.712|F1_1: 0.723|Prec0: 0.981|Rec0: 0.983|F1_0: 0.982\n",
      "Epoch 13 | Loss: 4.352 | Macro F1: 0.820| Acc: 0.946Prec1: 0.545|Rec1: 0.866|F1_1: 0.669|Prec0: 0.991|Rec0: 0.951|F1_0: 0.970\n",
      "Epoch 14 | Loss: 4.290 | Macro F1: 0.855| Acc: 0.967Prec1: 0.752|Rec1: 0.706|F1_1: 0.728|Prec0: 0.980|Rec0: 0.984|F1_0: 0.982\n",
      "Epoch 15 | Loss: 4.231 | Macro F1: 0.829| Acc: 0.950Prec1: 0.571|Rec1: 0.857|F1_1: 0.686|Prec0: 0.990|Rec0: 0.956|F1_0: 0.973\n",
      "Epoch 16 | Loss: 4.153 | Macro F1: 0.854| Acc: 0.966Prec1: 0.746|Rec1: 0.706|F1_1: 0.726|Prec0: 0.980|Rec0: 0.984|F1_0: 0.982\n",
      "Epoch 17 | Loss: 4.089 | Macro F1: 0.849| Acc: 0.960Prec1: 0.648|Rec1: 0.809|F1_1: 0.719|Prec0: 0.987|Rec0: 0.970|F1_0: 0.978\n",
      "Epoch 18 | Loss: 4.006 | Macro F1: 0.852| Acc: 0.963Prec1: 0.693|Rec1: 0.756|F1_1: 0.723|Prec0: 0.983|Rec0: 0.977|F1_0: 0.980\n",
      "Epoch 19 | Loss: 3.919 | Macro F1: 0.855| Acc: 0.965Prec1: 0.723|Rec1: 0.734|F1_1: 0.729|Prec0: 0.982|Rec0: 0.981|F1_0: 0.981\n",
      "Early stopping.\n",
      "Saved time-series plots to plots\\trial_2\n",
      "\n",
      "=== Trial 3 ===\n",
      "Threshold: 0.35, Use Past Y: True, Use Graph: False, Use Comments: False, Graph Type: sage\n",
      "Epoch 00 | Loss: 17.493 | Macro F1: 0.060| Acc: 0.063Prec1: 0.063|Rec1: 1.000|F1_1: 0.119|Prec0: 0.000|Rec0: 0.000|F1_0: 0.000\n",
      "Epoch 01 | Loss: 12.170 | Macro F1: 0.463| Acc: 0.625Prec1: 0.098|Rec1: 0.599|F1_1: 0.168|Prec0: 0.958|Rec0: 0.627|F1_0: 0.758\n",
      "Epoch 02 | Loss: 10.345 | Macro F1: 0.532| Acc: 0.733Prec1: 0.138|Rec1: 0.614|F1_1: 0.226|Prec0: 0.966|Rec0: 0.741|F1_0: 0.839\n",
      "Epoch 03 | Loss: 10.113 | Macro F1: 0.556| Acc: 0.730Prec1: 0.168|Rec1: 0.827|F1_1: 0.279|Prec0: 0.984|Rec0: 0.723|F1_0: 0.834\n",
      "Epoch 04 | Loss: 9.281 | Macro F1: 0.552| Acc: 0.736Prec1: 0.161|Rec1: 0.749|F1_1: 0.265|Prec0: 0.977|Rec0: 0.736|F1_0: 0.839\n",
      "Epoch 05 | Loss: 8.386 | Macro F1: 0.557| Acc: 0.731Prec1: 0.168|Rec1: 0.819|F1_1: 0.279|Prec0: 0.983|Rec0: 0.725|F1_0: 0.835\n",
      "Epoch 06 | Loss: 7.897 | Macro F1: 0.643| Acc: 0.830Prec1: 0.249|Rec1: 0.840|F1_1: 0.385|Prec0: 0.987|Rec0: 0.829|F1_0: 0.901\n",
      "Epoch 07 | Loss: 7.365 | Macro F1: 0.642| Acc: 0.829Prec1: 0.248|Rec1: 0.839|F1_1: 0.383|Prec0: 0.987|Rec0: 0.828|F1_0: 0.900\n",
      "Epoch 08 | Loss: 7.068 | Macro F1: 0.643| Acc: 0.829Prec1: 0.249|Rec1: 0.848|F1_1: 0.385|Prec0: 0.988|Rec0: 0.827|F1_0: 0.900\n",
      "Epoch 09 | Loss: 6.908 | Macro F1: 0.646| Acc: 0.832Prec1: 0.253|Rec1: 0.840|F1_1: 0.388|Prec0: 0.987|Rec0: 0.832|F1_0: 0.903\n",
      "Epoch 10 | Loss: 6.722 | Macro F1: 0.649| Acc: 0.837Prec1: 0.257|Rec1: 0.830|F1_1: 0.392|Prec0: 0.986|Rec0: 0.838|F1_0: 0.906\n",
      "Epoch 11 | Loss: 6.533 | Macro F1: 0.649| Acc: 0.838Prec1: 0.257|Rec1: 0.826|F1_1: 0.392|Prec0: 0.986|Rec0: 0.839|F1_0: 0.907\n",
      "Epoch 12 | Loss: 6.372 | Macro F1: 0.650| Acc: 0.839Prec1: 0.258|Rec1: 0.825|F1_1: 0.393|Prec0: 0.986|Rec0: 0.840|F1_0: 0.907\n",
      "Epoch 13 | Loss: 6.230 | Macro F1: 0.806| Acc: 0.943Prec1: 0.530|Rec1: 0.821|F1_1: 0.644|Prec0: 0.987|Rec0: 0.951|F1_0: 0.969\n",
      "Epoch 14 | Loss: 6.096 | Macro F1: 0.812| Acc: 0.945Prec1: 0.546|Rec1: 0.815|F1_1: 0.654|Prec0: 0.987|Rec0: 0.954|F1_0: 0.970\n",
      "Epoch 15 | Loss: 5.969 | Macro F1: 0.828| Acc: 0.951Prec1: 0.582|Rec1: 0.824|F1_1: 0.682|Prec0: 0.988|Rec0: 0.960|F1_0: 0.974\n",
      "Epoch 16 | Loss: 5.848 | Macro F1: 0.832| Acc: 0.953Prec1: 0.589|Rec1: 0.832|F1_1: 0.690|Prec0: 0.988|Rec0: 0.961|F1_0: 0.974\n",
      "Epoch 17 | Loss: 5.734 | Macro F1: 0.836| Acc: 0.954Prec1: 0.596|Rec1: 0.840|F1_1: 0.697|Prec0: 0.989|Rec0: 0.961|F1_0: 0.975\n",
      "Epoch 18 | Loss: 5.626 | Macro F1: 0.839| Acc: 0.955Prec1: 0.601|Rec1: 0.844|F1_1: 0.702|Prec0: 0.989|Rec0: 0.962|F1_0: 0.975\n",
      "Epoch 19 | Loss: 5.524 | Macro F1: 0.843| Acc: 0.956Prec1: 0.610|Rec1: 0.848|F1_1: 0.710|Prec0: 0.989|Rec0: 0.963|F1_0: 0.976\n",
      "Epoch 20 | Loss: 5.428 | Macro F1: 0.847| Acc: 0.957Prec1: 0.618|Rec1: 0.854|F1_1: 0.717|Prec0: 0.990|Rec0: 0.964|F1_0: 0.977\n",
      "Epoch 21 | Loss: 5.338 | Macro F1: 0.850| Acc: 0.958Prec1: 0.621|Rec1: 0.864|F1_1: 0.723|Prec0: 0.991|Rec0: 0.964|F1_0: 0.977\n",
      "Epoch 22 | Loss: 5.255 | Macro F1: 0.851| Acc: 0.958Prec1: 0.624|Rec1: 0.865|F1_1: 0.725|Prec0: 0.991|Rec0: 0.965|F1_0: 0.978\n",
      "Epoch 23 | Loss: 5.177 | Macro F1: 0.854| Acc: 0.959Prec1: 0.629|Rec1: 0.869|F1_1: 0.729|Prec0: 0.991|Rec0: 0.965|F1_0: 0.978\n",
      "Epoch 24 | Loss: 5.105 | Macro F1: 0.858| Acc: 0.960Prec1: 0.636|Rec1: 0.876|F1_1: 0.737|Prec0: 0.991|Rec0: 0.966|F1_0: 0.979\n",
      "Epoch 25 | Loss: 5.039 | Macro F1: 0.864| Acc: 0.962Prec1: 0.649|Rec1: 0.884|F1_1: 0.749|Prec0: 0.992|Rec0: 0.968|F1_0: 0.980\n",
      "Epoch 26 | Loss: 4.978 | Macro F1: 0.866| Acc: 0.963Prec1: 0.653|Rec1: 0.884|F1_1: 0.751|Prec0: 0.992|Rec0: 0.968|F1_0: 0.980\n",
      "Epoch 27 | Loss: 4.923 | Macro F1: 0.866| Acc: 0.963Prec1: 0.655|Rec1: 0.884|F1_1: 0.753|Prec0: 0.992|Rec0: 0.969|F1_0: 0.980\n",
      "Epoch 28 | Loss: 4.872 | Macro F1: 0.867| Acc: 0.963Prec1: 0.656|Rec1: 0.884|F1_1: 0.753|Prec0: 0.992|Rec0: 0.969|F1_0: 0.980\n",
      "Epoch 29 | Loss: 4.826 | Macro F1: 0.867| Acc: 0.963Prec1: 0.656|Rec1: 0.884|F1_1: 0.753|Prec0: 0.992|Rec0: 0.969|F1_0: 0.980\n",
      "Epoch 30 | Loss: 4.784 | Macro F1: 0.868| Acc: 0.964Prec1: 0.659|Rec1: 0.883|F1_1: 0.755|Prec0: 0.992|Rec0: 0.969|F1_0: 0.980\n",
      "Epoch 31 | Loss: 4.745 | Macro F1: 0.872| Acc: 0.965Prec1: 0.671|Rec1: 0.883|F1_1: 0.762|Prec0: 0.992|Rec0: 0.971|F1_0: 0.981\n",
      "Epoch 32 | Loss: 4.710 | Macro F1: 0.872| Acc: 0.965Prec1: 0.671|Rec1: 0.883|F1_1: 0.763|Prec0: 0.992|Rec0: 0.971|F1_0: 0.981\n",
      "Epoch 33 | Loss: 4.677 | Macro F1: 0.872| Acc: 0.965Prec1: 0.671|Rec1: 0.883|F1_1: 0.763|Prec0: 0.992|Rec0: 0.971|F1_0: 0.981\n",
      "Epoch 34 | Loss: 4.647 | Macro F1: 0.872| Acc: 0.965Prec1: 0.672|Rec1: 0.880|F1_1: 0.762|Prec0: 0.992|Rec0: 0.971|F1_0: 0.981\n",
      "Epoch 35 | Loss: 4.619 | Macro F1: 0.872| Acc: 0.965Prec1: 0.673|Rec1: 0.879|F1_1: 0.762|Prec0: 0.992|Rec0: 0.971|F1_0: 0.981\n",
      "Epoch 36 | Loss: 4.592 | Macro F1: 0.872| Acc: 0.965Prec1: 0.675|Rec1: 0.879|F1_1: 0.763|Prec0: 0.992|Rec0: 0.971|F1_0: 0.981\n",
      "Epoch 37 | Loss: 4.567 | Macro F1: 0.891| Acc: 0.972Prec1: 0.744|Rec1: 0.857|F1_1: 0.796|Prec0: 0.990|Rec0: 0.980|F1_0: 0.985\n",
      "Epoch 38 | Loss: 4.544 | Macro F1: 0.890| Acc: 0.972Prec1: 0.744|Rec1: 0.856|F1_1: 0.796|Prec0: 0.990|Rec0: 0.980|F1_0: 0.985\n",
      "Epoch 39 | Loss: 4.521 | Macro F1: 0.891| Acc: 0.972Prec1: 0.746|Rec1: 0.855|F1_1: 0.797|Prec0: 0.990|Rec0: 0.980|F1_0: 0.985\n",
      "Epoch 40 | Loss: 4.499 | Macro F1: 0.891| Acc: 0.972Prec1: 0.746|Rec1: 0.855|F1_1: 0.797|Prec0: 0.990|Rec0: 0.980|F1_0: 0.985\n",
      "Epoch 41 | Loss: 4.479 | Macro F1: 0.891| Acc: 0.972Prec1: 0.746|Rec1: 0.855|F1_1: 0.797|Prec0: 0.990|Rec0: 0.980|F1_0: 0.985\n",
      "Epoch 42 | Loss: 4.459 | Macro F1: 0.891| Acc: 0.972Prec1: 0.746|Rec1: 0.855|F1_1: 0.797|Prec0: 0.990|Rec0: 0.980|F1_0: 0.985\n",
      "Epoch 43 | Loss: 4.440 | Macro F1: 0.891| Acc: 0.972Prec1: 0.746|Rec1: 0.856|F1_1: 0.798|Prec0: 0.990|Rec0: 0.980|F1_0: 0.985\n",
      "Epoch 44 | Loss: 4.422 | Macro F1: 0.891| Acc: 0.972Prec1: 0.744|Rec1: 0.859|F1_1: 0.797|Prec0: 0.990|Rec0: 0.980|F1_0: 0.985\n",
      "Epoch 45 | Loss: 4.405 | Macro F1: 0.891| Acc: 0.972Prec1: 0.743|Rec1: 0.859|F1_1: 0.797|Prec0: 0.990|Rec0: 0.980|F1_0: 0.985\n",
      "Epoch 46 | Loss: 4.390 | Macro F1: 0.890| Acc: 0.972Prec1: 0.737|Rec1: 0.861|F1_1: 0.794|Prec0: 0.990|Rec0: 0.979|F1_0: 0.985\n",
      "Epoch 47 | Loss: 4.376 | Macro F1: 0.888| Acc: 0.971Prec1: 0.733|Rec1: 0.862|F1_1: 0.792|Prec0: 0.991|Rec0: 0.979|F1_0: 0.985\n",
      "Epoch 48 | Loss: 4.363 | Macro F1: 0.889| Acc: 0.971Prec1: 0.732|Rec1: 0.864|F1_1: 0.793|Prec0: 0.991|Rec0: 0.979|F1_0: 0.985\n",
      "Early stopping.\n",
      "Saved time-series plots to plots\\trial_3\n",
      "\n",
      "=== Trial 4 ===\n",
      "Threshold: 0.35, Use Past Y: True, Use Graph: False, Use Comments: True, Graph Type: sage\n",
      "Epoch 00 | Loss: 16.441 | Macro F1: 0.354| Acc: 0.404Prec1: 0.095|Rec1: 0.985|F1_1: 0.173|Prec0: 0.997|Rec0: 0.365|F1_0: 0.534\n",
      "Epoch 01 | Loss: 9.732 | Macro F1: 0.549| Acc: 0.700Prec1: 0.170|Rec1: 0.961|F1_1: 0.289|Prec0: 0.996|Rec0: 0.682|F1_0: 0.810\n",
      "Epoch 02 | Loss: 8.193 | Macro F1: 0.529| Acc: 0.668Prec1: 0.159|Rec1: 0.989|F1_1: 0.274|Prec0: 0.999|Rec0: 0.646|F1_0: 0.785\n",
      "Epoch 03 | Loss: 7.422 | Macro F1: 0.591| Acc: 0.751Prec1: 0.202|Rec1: 0.989|F1_1: 0.335|Prec0: 0.999|Rec0: 0.735|F1_0: 0.847\n",
      "Epoch 04 | Loss: 6.764 | Macro F1: 0.647| Acc: 0.821Prec1: 0.253|Rec1: 0.933|F1_1: 0.399|Prec0: 0.994|Rec0: 0.814|F1_0: 0.895\n",
      "Epoch 05 | Loss: 5.808 | Macro F1: 0.661| Acc: 0.837Prec1: 0.270|Rec1: 0.920|F1_1: 0.417|Prec0: 0.994|Rec0: 0.831|F1_0: 0.905\n",
      "Epoch 06 | Loss: 5.500 | Macro F1: 0.672| Acc: 0.849Prec1: 0.283|Rec1: 0.906|F1_1: 0.431|Prec0: 0.993|Rec0: 0.845|F1_0: 0.913\n",
      "Epoch 07 | Loss: 5.251 | Macro F1: 0.679| Acc: 0.856Prec1: 0.292|Rec1: 0.897|F1_1: 0.441|Prec0: 0.992|Rec0: 0.853|F1_0: 0.917\n",
      "Epoch 08 | Loss: 4.993 | Macro F1: 0.680| Acc: 0.853Prec1: 0.292|Rec1: 0.926|F1_1: 0.444|Prec0: 0.994|Rec0: 0.848|F1_0: 0.915\n",
      "Epoch 09 | Loss: 4.778 | Macro F1: 0.687| Acc: 0.860Prec1: 0.302|Rec1: 0.922|F1_1: 0.455|Prec0: 0.994|Rec0: 0.856|F1_0: 0.920\n",
      "Epoch 10 | Loss: 4.688 | Macro F1: 0.810| Acc: 0.937Prec1: 0.503|Rec1: 0.938|F1_1: 0.655|Prec0: 0.996|Rec0: 0.937|F1_0: 0.966\n",
      "Epoch 11 | Loss: 4.542 | Macro F1: 0.822| Acc: 0.943Prec1: 0.526|Rec1: 0.940|F1_1: 0.675|Prec0: 0.996|Rec0: 0.943|F1_0: 0.969\n",
      "Epoch 12 | Loss: 4.363 | Macro F1: 0.849| Acc: 0.956Prec1: 0.600|Rec1: 0.910|F1_1: 0.723|Prec0: 0.994|Rec0: 0.959|F1_0: 0.976\n",
      "Epoch 13 | Loss: 4.318 | Macro F1: 0.866| Acc: 0.964Prec1: 0.660|Rec1: 0.875|F1_1: 0.752|Prec0: 0.991|Rec0: 0.970|F1_0: 0.980\n",
      "Epoch 14 | Loss: 4.313 | Macro F1: 0.841| Acc: 0.951Prec1: 0.565|Rec1: 0.954|F1_1: 0.710|Prec0: 0.997|Rec0: 0.950|F1_0: 0.973\n",
      "Epoch 15 | Loss: 4.061 | Macro F1: 0.855| Acc: 0.958Prec1: 0.609|Rec1: 0.923|F1_1: 0.734|Prec0: 0.995|Rec0: 0.960|F1_0: 0.977\n",
      "Epoch 16 | Loss: 3.947 | Macro F1: 0.867| Acc: 0.962Prec1: 0.640|Rec1: 0.918|F1_1: 0.754|Prec0: 0.994|Rec0: 0.965|F1_0: 0.979\n",
      "Epoch 17 | Loss: 3.869 | Macro F1: 0.879| Acc: 0.967Prec1: 0.675|Rec1: 0.912|F1_1: 0.776|Prec0: 0.994|Rec0: 0.970|F1_0: 0.982\n",
      "Epoch 18 | Loss: 3.806 | Macro F1: 0.882| Acc: 0.967Prec1: 0.681|Rec1: 0.916|F1_1: 0.781|Prec0: 0.994|Rec0: 0.971|F1_0: 0.982\n",
      "Epoch 19 | Loss: 3.739 | Macro F1: 0.882| Acc: 0.967Prec1: 0.676|Rec1: 0.926|F1_1: 0.781|Prec0: 0.995|Rec0: 0.970|F1_0: 0.982\n",
      "Epoch 20 | Loss: 3.690 | Macro F1: 0.885| Acc: 0.968Prec1: 0.686|Rec1: 0.925|F1_1: 0.787|Prec0: 0.995|Rec0: 0.971|F1_0: 0.983\n",
      "Epoch 21 | Loss: 3.658 | Macro F1: 0.890| Acc: 0.970Prec1: 0.703|Rec1: 0.919|F1_1: 0.797|Prec0: 0.994|Rec0: 0.974|F1_0: 0.984\n",
      "Epoch 22 | Loss: 3.629 | Macro F1: 0.883| Acc: 0.968Prec1: 0.677|Rec1: 0.933|F1_1: 0.785|Prec0: 0.995|Rec0: 0.970|F1_0: 0.982\n",
      "Epoch 23 | Loss: 3.573 | Macro F1: 0.883| Acc: 0.967Prec1: 0.673|Rec1: 0.938|F1_1: 0.784|Prec0: 0.996|Rec0: 0.969|F1_0: 0.982\n",
      "Epoch 24 | Loss: 3.529 | Macro F1: 0.888| Acc: 0.969Prec1: 0.689|Rec1: 0.932|F1_1: 0.792|Prec0: 0.995|Rec0: 0.972|F1_0: 0.983\n",
      "Epoch 25 | Loss: 3.494 | Macro F1: 0.892| Acc: 0.971Prec1: 0.703|Rec1: 0.927|F1_1: 0.800|Prec0: 0.995|Rec0: 0.973|F1_0: 0.984\n",
      "Epoch 26 | Loss: 3.472 | Macro F1: 0.893| Acc: 0.971Prec1: 0.703|Rec1: 0.932|F1_1: 0.801|Prec0: 0.995|Rec0: 0.973|F1_0: 0.984\n",
      "Epoch 27 | Loss: 3.435 | Macro F1: 0.897| Acc: 0.972Prec1: 0.715|Rec1: 0.931|F1_1: 0.809|Prec0: 0.995|Rec0: 0.975|F1_0: 0.985\n",
      "Epoch 28 | Loss: 3.419 | Macro F1: 0.895| Acc: 0.971Prec1: 0.708|Rec1: 0.933|F1_1: 0.805|Prec0: 0.995|Rec0: 0.974|F1_0: 0.985\n",
      "Epoch 29 | Loss: 3.383 | Macro F1: 0.898| Acc: 0.973Prec1: 0.720|Rec1: 0.930|F1_1: 0.811|Prec0: 0.995|Rec0: 0.976|F1_0: 0.985\n",
      "Epoch 30 | Loss: 3.376 | Macro F1: 0.898| Acc: 0.972Prec1: 0.717|Rec1: 0.933|F1_1: 0.811|Prec0: 0.995|Rec0: 0.975|F1_0: 0.985\n",
      "Epoch 31 | Loss: 3.336 | Macro F1: 0.899| Acc: 0.973Prec1: 0.722|Rec1: 0.932|F1_1: 0.813|Prec0: 0.995|Rec0: 0.976|F1_0: 0.985\n",
      "Epoch 32 | Loss: 3.326 | Macro F1: 0.897| Acc: 0.972Prec1: 0.715|Rec1: 0.933|F1_1: 0.809|Prec0: 0.995|Rec0: 0.975|F1_0: 0.985\n",
      "Epoch 33 | Loss: 3.296 | Macro F1: 0.899| Acc: 0.973Prec1: 0.722|Rec1: 0.932|F1_1: 0.813|Prec0: 0.995|Rec0: 0.976|F1_0: 0.985\n",
      "Epoch 34 | Loss: 3.283 | Macro F1: 0.897| Acc: 0.972Prec1: 0.715|Rec1: 0.932|F1_1: 0.809|Prec0: 0.995|Rec0: 0.975|F1_0: 0.985\n",
      "Epoch 35 | Loss: 3.260 | Macro F1: 0.898| Acc: 0.973Prec1: 0.720|Rec1: 0.930|F1_1: 0.811|Prec0: 0.995|Rec0: 0.976|F1_0: 0.985\n",
      "Epoch 36 | Loss: 3.247 | Macro F1: 0.897| Acc: 0.972Prec1: 0.716|Rec1: 0.931|F1_1: 0.809|Prec0: 0.995|Rec0: 0.975|F1_0: 0.985\n",
      "Early stopping.\n",
      "Saved time-series plots to plots\\trial_4\n",
      "\n",
      "=== Trial 5 ===\n",
      "Threshold: 0.35, Use Past Y: True, Use Graph: True, Use Comments: False, Graph Type: sage\n",
      "Epoch 00 | Loss: 15.857 | Macro F1: 0.463| Acc: 0.705Prec1: 0.063|Rec1: 0.265|F1_1: 0.102|Prec0: 0.937|Rec0: 0.735|F1_0: 0.824\n",
      "Epoch 01 | Loss: 18.138 | Macro F1: 0.394| Acc: 0.549Prec1: 0.050|Rec1: 0.338|F1_1: 0.087|Prec0: 0.926|Rec0: 0.564|F1_0: 0.701\n",
      "Epoch 02 | Loss: 11.584 | Macro F1: 0.542| Acc: 0.902Prec1: 0.155|Rec1: 0.122|F1_1: 0.137|Prec0: 0.941|Rec0: 0.955|F1_0: 0.948\n",
      "Epoch 03 | Loss: 9.108 | Macro F1: 0.586| Acc: 0.940Prec1: 0.626|Rec1: 0.122|F1_1: 0.204|Prec0: 0.944|Rec0: 0.995|F1_0: 0.969\n",
      "Epoch 04 | Loss: 8.240 | Macro F1: 0.663| Acc: 0.945Prec1: 0.689|Rec1: 0.239|F1_1: 0.355|Prec0: 0.951|Rec0: 0.993|F1_0: 0.971\n",
      "Epoch 05 | Loss: 7.543 | Macro F1: 0.772| Acc: 0.956Prec1: 0.740|Rec1: 0.459|F1_1: 0.567|Prec0: 0.964|Rec0: 0.989|F1_0: 0.977\n",
      "Epoch 06 | Loss: 6.777 | Macro F1: 0.839| Acc: 0.964Prec1: 0.738|Rec1: 0.660|F1_1: 0.697|Prec0: 0.977|Rec0: 0.984|F1_0: 0.981\n",
      "Epoch 07 | Loss: 6.128 | Macro F1: 0.850| Acc: 0.964Prec1: 0.713|Rec1: 0.725|F1_1: 0.719|Prec0: 0.981|Rec0: 0.980|F1_0: 0.981\n",
      "Epoch 08 | Loss: 5.585 | Macro F1: 0.869| Acc: 0.968Prec1: 0.725|Rec1: 0.790|F1_1: 0.756|Prec0: 0.986|Rec0: 0.980|F1_0: 0.983\n",
      "Epoch 09 | Loss: 5.223 | Macro F1: 0.877| Acc: 0.969Prec1: 0.734|Rec1: 0.811|F1_1: 0.770|Prec0: 0.987|Rec0: 0.980|F1_0: 0.984\n",
      "Epoch 10 | Loss: 4.953 | Macro F1: 0.888| Acc: 0.972Prec1: 0.746|Rec1: 0.841|F1_1: 0.791|Prec0: 0.989|Rec0: 0.981|F1_0: 0.985\n",
      "Epoch 11 | Loss: 4.779 | Macro F1: 0.890| Acc: 0.972Prec1: 0.749|Rec1: 0.848|F1_1: 0.795|Prec0: 0.990|Rec0: 0.981|F1_0: 0.985\n",
      "Epoch 12 | Loss: 4.679 | Macro F1: 0.891| Acc: 0.973Prec1: 0.750|Rec1: 0.849|F1_1: 0.797|Prec0: 0.990|Rec0: 0.981|F1_0: 0.985\n",
      "Epoch 13 | Loss: 4.619 | Macro F1: 0.893| Acc: 0.973Prec1: 0.752|Rec1: 0.855|F1_1: 0.800|Prec0: 0.990|Rec0: 0.981|F1_0: 0.985\n",
      "Epoch 14 | Loss: 4.576 | Macro F1: 0.893| Acc: 0.973Prec1: 0.751|Rec1: 0.855|F1_1: 0.800|Prec0: 0.990|Rec0: 0.981|F1_0: 0.985\n",
      "Epoch 15 | Loss: 4.540 | Macro F1: 0.893| Acc: 0.973Prec1: 0.750|Rec1: 0.856|F1_1: 0.800|Prec0: 0.990|Rec0: 0.981|F1_0: 0.985\n",
      "Epoch 16 | Loss: 4.506 | Macro F1: 0.892| Acc: 0.973Prec1: 0.749|Rec1: 0.856|F1_1: 0.799|Prec0: 0.990|Rec0: 0.981|F1_0: 0.985\n",
      "Epoch 17 | Loss: 4.477 | Macro F1: 0.892| Acc: 0.973Prec1: 0.748|Rec1: 0.857|F1_1: 0.799|Prec0: 0.990|Rec0: 0.980|F1_0: 0.985\n",
      "Epoch 18 | Loss: 4.454 | Macro F1: 0.891| Acc: 0.972Prec1: 0.744|Rec1: 0.858|F1_1: 0.797|Prec0: 0.990|Rec0: 0.980|F1_0: 0.985\n",
      "Early stopping.\n",
      "Saved time-series plots to plots\\trial_5\n",
      "\n",
      "=== Trial 6 ===\n",
      "Threshold: 0.35, Use Past Y: True, Use Graph: True, Use Comments: True, Graph Type: sage\n",
      "Epoch 00 | Loss: 15.651 | Macro F1: 0.466| Acc: 0.713Prec1: 0.064|Rec1: 0.257|F1_1: 0.102|Prec0: 0.937|Rec0: 0.744|F1_0: 0.829\n",
      "Epoch 01 | Loss: 8.379 | Macro F1: 0.669| Acc: 0.854Prec1: 0.281|Rec1: 0.840|F1_1: 0.422|Prec0: 0.988|Rec0: 0.855|F1_0: 0.916\n",
      "Epoch 02 | Loss: 6.085 | Macro F1: 0.779| Acc: 0.931Prec1: 0.475|Rec1: 0.796|F1_1: 0.595|Prec0: 0.986|Rec0: 0.940|F1_0: 0.962\n",
      "Epoch 03 | Loss: 5.381 | Macro F1: 0.809| Acc: 0.940Prec1: 0.515|Rec1: 0.881|F1_1: 0.650|Prec0: 0.992|Rec0: 0.944|F1_0: 0.967\n",
      "Epoch 04 | Loss: 4.781 | Macro F1: 0.854| Acc: 0.964Prec1: 0.698|Rec1: 0.758|F1_1: 0.727|Prec0: 0.984|Rec0: 0.978|F1_0: 0.981\n",
      "Epoch 05 | Loss: 4.640 | Macro F1: 0.872| Acc: 0.968Prec1: 0.726|Rec1: 0.802|F1_1: 0.762|Prec0: 0.987|Rec0: 0.979|F1_0: 0.983\n",
      "Epoch 06 | Loss: 4.370 | Macro F1: 0.870| Acc: 0.964Prec1: 0.662|Rec1: 0.890|F1_1: 0.759|Prec0: 0.992|Rec0: 0.969|F1_0: 0.981\n",
      "Epoch 07 | Loss: 4.019 | Macro F1: 0.889| Acc: 0.971Prec1: 0.730|Rec1: 0.868|F1_1: 0.793|Prec0: 0.991|Rec0: 0.978|F1_0: 0.985\n",
      "Epoch 08 | Loss: 3.787 | Macro F1: 0.897| Acc: 0.974Prec1: 0.758|Rec1: 0.866|F1_1: 0.808|Prec0: 0.991|Rec0: 0.981|F1_0: 0.986\n",
      "Epoch 09 | Loss: 3.614 | Macro F1: 0.902| Acc: 0.975Prec1: 0.756|Rec1: 0.890|F1_1: 0.818|Prec0: 0.992|Rec0: 0.981|F1_0: 0.986\n",
      "Epoch 10 | Loss: 3.492 | Macro F1: 0.905| Acc: 0.976Prec1: 0.762|Rec1: 0.896|F1_1: 0.824|Prec0: 0.993|Rec0: 0.981|F1_0: 0.987\n",
      "Epoch 11 | Loss: 3.399 | Macro F1: 0.906| Acc: 0.976Prec1: 0.756|Rec1: 0.908|F1_1: 0.825|Prec0: 0.994|Rec0: 0.980|F1_0: 0.987\n",
      "Epoch 12 | Loss: 3.324 | Macro F1: 0.907| Acc: 0.976Prec1: 0.758|Rec1: 0.911|F1_1: 0.828|Prec0: 0.994|Rec0: 0.980|F1_0: 0.987\n",
      "Epoch 13 | Loss: 3.269 | Macro F1: 0.908| Acc: 0.976Prec1: 0.758|Rec1: 0.915|F1_1: 0.829|Prec0: 0.994|Rec0: 0.980|F1_0: 0.987\n",
      "Epoch 14 | Loss: 3.225 | Macro F1: 0.909| Acc: 0.976Prec1: 0.756|Rec1: 0.921|F1_1: 0.830|Prec0: 0.995|Rec0: 0.980|F1_0: 0.987\n",
      "Epoch 15 | Loss: 3.189 | Macro F1: 0.908| Acc: 0.976Prec1: 0.754|Rec1: 0.922|F1_1: 0.830|Prec0: 0.995|Rec0: 0.980|F1_0: 0.987\n",
      "Epoch 16 | Loss: 3.163 | Macro F1: 0.909| Acc: 0.976Prec1: 0.754|Rec1: 0.926|F1_1: 0.832|Prec0: 0.995|Rec0: 0.980|F1_0: 0.987\n",
      "Epoch 17 | Loss: 3.139 | Macro F1: 0.910| Acc: 0.976Prec1: 0.755|Rec1: 0.926|F1_1: 0.832|Prec0: 0.995|Rec0: 0.980|F1_0: 0.987\n",
      "Epoch 18 | Loss: 3.119 | Macro F1: 0.909| Acc: 0.976Prec1: 0.751|Rec1: 0.927|F1_1: 0.830|Prec0: 0.995|Rec0: 0.979|F1_0: 0.987\n",
      "Epoch 19 | Loss: 3.101 | Macro F1: 0.908| Acc: 0.976Prec1: 0.752|Rec1: 0.926|F1_1: 0.830|Prec0: 0.995|Rec0: 0.979|F1_0: 0.987\n",
      "Epoch 20 | Loss: 3.087 | Macro F1: 0.909| Acc: 0.976Prec1: 0.753|Rec1: 0.926|F1_1: 0.830|Prec0: 0.995|Rec0: 0.979|F1_0: 0.987\n",
      "Epoch 21 | Loss: 3.073 | Macro F1: 0.909| Acc: 0.976Prec1: 0.755|Rec1: 0.926|F1_1: 0.831|Prec0: 0.995|Rec0: 0.980|F1_0: 0.987\n",
      "Epoch 22 | Loss: 3.061 | Macro F1: 0.909| Acc: 0.976Prec1: 0.753|Rec1: 0.926|F1_1: 0.831|Prec0: 0.995|Rec0: 0.979|F1_0: 0.987\n",
      "Early stopping.\n",
      "Saved time-series plots to plots\\trial_6\n",
      "\n",
      "===== SWEEP COMPLETE =====\n",
      "Best configuration:\n",
      "{'trial': 6, 'threshold': 0.35, 'use_past_y': True, 'use_graph': True, 'use_comments': True, 'precision_class_1': 0.7553648068615497, 'recall_class_1': 0.9255039439007406, 'precision_class_0': 0.9948826008422668, 'recall_class_0': 0.9797237208745007, 'f1_class_1': 0.8318235476244321, 'f1_class_0': 0.9872449691610693, 'macro_f1': 0.9095342583927507, 'accuracy': 0.9762883186340332}\n",
      "\n",
      "Results saved to full_sweep_results.csv\n",
      "Best model saved to best_model.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "COMMENT_HIDDEN = 128\n",
    "USER_HIDDEN = 128\n",
    "\n",
    "PLOTS_ROOT = \"plots\"\n",
    "os.makedirs(PLOTS_ROOT, exist_ok=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 1) Infer feature dimension\n",
    "# ------------------------------------------------------\n",
    "any_user = next(\n",
    "    u for u in temporal_graph.user_nodes.values()\n",
    "    if len(u.comments) > 0\n",
    ")\n",
    "any_comment = next(iter(any_user.comments.values()))\n",
    "COMMENT_DIM = any_comment.feature_vec.shape[0]\n",
    "print(\"COMMENT_DIM =\", COMMENT_DIM)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2) Temporal split\n",
    "# ------------------------------------------------------\n",
    "T = len(temporal_graph.time_intervall.time_intervalls)\n",
    "\n",
    "T_TRAIN = int(0.8 * T)\n",
    "T_VAL   = int(1 * T)\n",
    "\n",
    "train_ts = list(range(0, T_TRAIN))\n",
    "val_ts   = list(range(T_TRAIN, T_VAL))\n",
    "\n",
    "print(f\"Train: 0 → {T_TRAIN-1}\")\n",
    "print(f\"Val  : {T_VAL-1}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3) Metrics\n",
    "# ------------------------------------------------------\n",
    "def compute_metrics(logits, labels, threshold):\n",
    "\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = (probs > threshold).float()\n",
    "    labels_bin = (labels >= 0.5).float()\n",
    "\n",
    "    tp1 = ((preds == 1) & (labels_bin == 1)).sum().item()\n",
    "    fp1 = ((preds == 1) & (labels_bin == 0)).sum().item()\n",
    "    fn1 = ((preds == 0) & (labels_bin == 1)).sum().item()\n",
    "\n",
    "    tp0 = ((preds == 0) & (labels_bin == 0)).sum().item()\n",
    "    fp0 = ((preds == 0) & (labels_bin == 1)).sum().item()\n",
    "    fn0 = ((preds == 1) & (labels_bin == 0)).sum().item()\n",
    "\n",
    "    prec1 = tp1 / (tp1 + fp1 + 1e-8)\n",
    "    rec1  = tp1 / (tp1 + fn1 + 1e-8)\n",
    "    f1_1  = 2 * prec1 * rec1 / (prec1 + rec1 + 1e-8)\n",
    "\n",
    "    prec0 = tp0 / (tp0 + fp0 + 1e-8)\n",
    "    rec0  = tp0 / (tp0 + fn0 + 1e-8)\n",
    "    f1_0  = 2 * prec0 * rec0 / (prec0 + rec0 + 1e-8)\n",
    "\n",
    "    macro_f1 = (f1_0 + f1_1) / 2.0\n",
    "    acc = (preds == labels_bin).float().mean().item()\n",
    "\n",
    "    return {\n",
    "        \"precision_class_1\": prec1,\n",
    "        \"recall_class_1\": rec1,\n",
    "        \"precision_class_0\": prec0,\n",
    "        \"recall_class_0\": rec0,\n",
    "        \"f1_class_1\": f1_1,\n",
    "        \"f1_class_0\": f1_0,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"accuracy\": acc\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4) Time-Series Plot Generator (NEW)\n",
    "# ------------------------------------------------------\n",
    "def generate_trial_plots(trial_id, history):\n",
    "\n",
    "    trial_dir = os.path.join(PLOTS_ROOT, f\"trial_{trial_id}\")\n",
    "    os.makedirs(trial_dir, exist_ok=True)\n",
    "\n",
    "    epochs = range(1, len(history[\"loss\"]) + 1)\n",
    "\n",
    "    # Training Loss\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, history[\"loss\"])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Over Time\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(trial_dir, \"loss_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Precision\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, history[\"precision_class_0\"], label=\"Precision Class 0\")\n",
    "    plt.plot(epochs, history[\"precision_class_1\"], label=\"Precision Class 1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Precision Over Time\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(trial_dir, \"precision_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Recall\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, history[\"recall_class_0\"], label=\"Recall Class 0\")\n",
    "    plt.plot(epochs, history[\"recall_class_1\"], label=\"Recall Class 1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Recall Over Time\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(trial_dir, \"recall_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # F1\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, history[\"f1_class_0\"], label=\"F1 Class 0\")\n",
    "    plt.plot(epochs, history[\"f1_class_1\"], label=\"F1 Class 1\")\n",
    "    plt.plot(epochs, history[\"macro_f1\"], label=\"Macro F1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.title(\"F1 Development\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(trial_dir, \"f1_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, history[\"accuracy\"])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy Over Time\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(trial_dir, \"accuracy_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved time-series plots to {trial_dir}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5) Sweep configuration (UNCHANGED)\n",
    "# ------------------------------------------------------\n",
    "thresholds  = [0.35]\n",
    "use_past_y_opts   = [False]\n",
    "use_graph_opts    = [True]\n",
    "use_comments_opts = [True]\n",
    "graph_types = [\"sage\"]\n",
    "\n",
    "EPOCHS = 50\n",
    "PATIENCE = 5\n",
    "LR = 5e-4\n",
    "\n",
    "results = []\n",
    "best_macro_f1 = -1\n",
    "best_config = None\n",
    "best_model_path = \"best_model.pt\"\n",
    "\n",
    "trial_id = 0\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6) Sweep (ONLY metric storage added)\n",
    "# ------------------------------------------------------\n",
    "for (thresh,\n",
    "     use_past_y,\n",
    "     use_graph,\n",
    "    graph_types,\n",
    "     use_comments) in itertools.product(\n",
    "        thresholds,\n",
    "        use_past_y_opts,\n",
    "        use_graph_opts,\n",
    "    graph_types,\n",
    "        use_comments_opts\n",
    "    ):\n",
    "\n",
    "    if not use_comments and not use_past_y:\n",
    "        continue\n",
    "\n",
    "    trial_id += 1\n",
    "    print(f\"\\n=== Trial {trial_id} ===\")\n",
    "    print(f\"Threshold: {thresh}, Use Past Y: {use_past_y}, \"\n",
    "          f\"Use Graph: {use_graph}, Use Comments: {use_comments}, Graph Type: {graph_types}\")  \n",
    "    \n",
    "    model = TemporalTruthModel(\n",
    "        COMMENT_DIM,\n",
    "        use_past_y=use_past_y,\n",
    "        use_graph=use_graph,\n",
    "        use_comments=use_comments,\n",
    "        graph_type=graph_types\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=LR,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    user_ids = list(temporal_graph.user_nodes.keys())\n",
    "\n",
    "    best_trial_macro = -1\n",
    "    patience_ctr = 0\n",
    "\n",
    "    history = {\n",
    "        \"loss\": [],\n",
    "        \"precision_class_0\": [],\n",
    "        \"precision_class_1\": [],\n",
    "        \"recall_class_0\": [],\n",
    "        \"recall_class_1\": [],\n",
    "        \"f1_class_0\": [],\n",
    "        \"f1_class_1\": [],\n",
    "        \"macro_f1\": [],\n",
    "        \"accuracy\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        model.train()\n",
    "        user_states = {u: torch.zeros(USER_HIDDEN, device=DEVICE)\n",
    "                       for u in user_ids}\n",
    "\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for t in train_ts:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits, labels, user_states = model.forward_one_step(\n",
    "                temporal_graph, t, user_states\n",
    "            )\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            for u in user_states:\n",
    "                user_states[u] = user_states[u].detach()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            user_states = {u: torch.zeros(USER_HIDDEN, device=DEVICE)\n",
    "                           for u in user_ids}\n",
    "\n",
    "            val_logits_all = []\n",
    "            val_labels_all = []\n",
    "\n",
    "            for t in val_ts:\n",
    "                logits, labels, user_states = model.forward_one_step(\n",
    "                    temporal_graph, t, user_states\n",
    "                )\n",
    "                val_logits_all.append(logits)\n",
    "                val_labels_all.append(labels)\n",
    "\n",
    "            val_logits = torch.cat(val_logits_all)\n",
    "            val_labels = torch.cat(val_labels_all)\n",
    "\n",
    "            metrics = compute_metrics(val_logits, val_labels, thresh)\n",
    "\n",
    "        # Store history\n",
    "        history[\"loss\"].append(total_loss)\n",
    "        for k in metrics:\n",
    "            history[k].append(metrics[k])\n",
    "\n",
    "        macro_f1 = metrics[\"macro_f1\"]\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} | Loss: {total_loss:.3f} | \"\n",
    "              f\"Macro F1: {macro_f1:.3f}| Acc: {metrics['accuracy']:.3f}\"\n",
    "              f\"Prec1: {metrics['precision_class_1']:.3f}|Rec1: {metrics['recall_class_1']:.3f}|F1_1: {metrics['f1_class_1']:.3f}\"\n",
    "              f\"|Prec0: {metrics['precision_class_0']:.3f}|Rec0: {metrics['recall_class_0']:.3f}|F1_0: {metrics['f1_class_0']:.3f}\")\n",
    "\n",
    "        if macro_f1 > best_trial_macro + 1e-4:\n",
    "            best_trial_macro = macro_f1\n",
    "            best_trial_metrics = metrics\n",
    "            patience_ctr = 0\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "            if patience_ctr >= PATIENCE:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    generate_trial_plots(trial_id, history)\n",
    "\n",
    "    results.append({\n",
    "        \"trial\": trial_id,\n",
    "        \"threshold\": thresh,\n",
    "        \"use_past_y\": use_past_y,\n",
    "        \"use_graph\": use_graph,\n",
    "        \"use_comments\": use_comments,\n",
    "        **best_trial_metrics\n",
    "    })\n",
    "\n",
    "    if best_trial_macro > best_macro_f1:\n",
    "        best_macro_f1 = best_trial_macro\n",
    "        best_config = results[-1]\n",
    "        torch.save(model.cpu().state_dict(), best_model_path)\n",
    "        model.to(DEVICE)\n",
    "\n",
    "    del model\n",
    "    del optimizer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 7) Save results (UNCHANGED)\n",
    "# ------------------------------------------------------\n",
    "results_df = pd.DataFrame(results).sort_values(\n",
    "    \"macro_f1\", ascending=False\n",
    ")\n",
    "\n",
    "results_df.to_csv(\"full_sweep_results.csv\", index=False)\n",
    "\n",
    "print(\"\\n===== SWEEP COMPLETE =====\")\n",
    "print(\"Best configuration:\")\n",
    "print(best_config)\n",
    "print(\"\\nResults saved to full_sweep_results.csv\")\n",
    "print(\"Best model saved to best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc20017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved plots saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# TEMPORAL CLUSTERING + INFLUENCE ANALYSIS\n",
    "# WITH PLOTS\n",
    "# ==========================================\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "T = len(temporal_graph.time_intervall.time_intervalls)\n",
    "user_ids = list(temporal_graph.user_nodes.keys())\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1️⃣ BUILD STATIC GRAPH\n",
    "# -----------------------------------------\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for u in user_ids:\n",
    "    G.add_node(u)\n",
    "\n",
    "for u_id, node in temporal_graph.user_nodes.items():\n",
    "    for neigh in node.outgoing_edges:\n",
    "        G.add_edge(u_id, str(neigh.user_id))\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2️⃣ BUILD DANGEROUS MATRIX\n",
    "# -----------------------------------------\n",
    "danger = {\n",
    "    u: [\n",
    "        1 if flag == 1.0 else 0\n",
    "        for flag in temporal_graph.user_nodes[u].truth_flag_intervall\n",
    "    ]\n",
    "    for u in user_ids\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# STORAGE ARRAYS\n",
    "# ==========================================\n",
    "danger_counts = []\n",
    "densities = []\n",
    "largest_components = []\n",
    "assortativities = []\n",
    "d2d_ratios = []\n",
    "risk_ratios = []\n",
    "risk_times = []\n",
    "\n",
    "# ==========================================\n",
    "# TEMPORAL CLUSTERING\n",
    "# ==========================================\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    dangerous_users_t = [\n",
    "        u for u in user_ids if danger[u][t] == 1\n",
    "    ]\n",
    "\n",
    "    danger_counts.append(len(dangerous_users_t))\n",
    "\n",
    "    if len(dangerous_users_t) == 0:\n",
    "        densities.append(0)\n",
    "        largest_components.append(0)\n",
    "        assortativities.append(0)\n",
    "        d2d_ratios.append(0)\n",
    "        continue\n",
    "\n",
    "    G_t = G.subgraph(dangerous_users_t)\n",
    "\n",
    "    density = nx.density(G_t)\n",
    "    components = list(nx.weakly_connected_components(G_t))\n",
    "    largest_component = max(len(c) for c in components)\n",
    "\n",
    "    attr = {u: danger[u][t] for u in user_ids}\n",
    "    nx.set_node_attributes(G, attr, \"danger_t\")\n",
    "    assort = nx.attribute_assortativity_coefficient(G, \"danger_t\")\n",
    "\n",
    "    d2d = 0\n",
    "    total_edges = 0\n",
    "    for u, v in G.edges():\n",
    "        if danger[u][t] == 1 and danger[v][t] == 1:\n",
    "            d2d += 1\n",
    "        total_edges += 1\n",
    "\n",
    "    ratio = d2d / total_edges if total_edges > 0 else 0\n",
    "\n",
    "    densities.append(density)\n",
    "    largest_components.append(largest_component)\n",
    "    assortativities.append(assort)\n",
    "    d2d_ratios.append(ratio)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# TEMPORAL INFLUENCE\n",
    "# ==========================================\n",
    "\n",
    "for t in range(T - 1):\n",
    "\n",
    "    became_with_exposure = 0\n",
    "    total_with_exposure = 0\n",
    "\n",
    "    became_without_exposure = 0\n",
    "    total_without_exposure = 0\n",
    "\n",
    "    for u in user_ids:\n",
    "\n",
    "        if danger[u][t] == 0:\n",
    "\n",
    "            node = temporal_graph.user_nodes[u]\n",
    "\n",
    "            exposed = False\n",
    "            for neigh in node.ingoing_edges:\n",
    "                v = str(neigh.user_id)\n",
    "                if danger[v][t] == 1:\n",
    "                    exposed = True\n",
    "                    break\n",
    "\n",
    "            became_danger = danger[u][t+1] == 1\n",
    "\n",
    "            if exposed:\n",
    "                total_with_exposure += 1\n",
    "                if became_danger:\n",
    "                    became_with_exposure += 1\n",
    "            else:\n",
    "                total_without_exposure += 1\n",
    "                if became_danger:\n",
    "                    became_without_exposure += 1\n",
    "\n",
    "    if total_with_exposure == 0 or total_without_exposure == 0:\n",
    "        continue\n",
    "\n",
    "    p_exp = became_with_exposure / total_with_exposure\n",
    "    p_noexp = became_without_exposure / total_without_exposure\n",
    "\n",
    "    risk_ratio = p_exp / p_noexp if p_noexp > 0 else np.nan\n",
    "\n",
    "    risk_ratios.append(risk_ratio)\n",
    "    risk_times.append(t)\n",
    "\n",
    "# ==========================================\n",
    "#  PUBLICATION-READY PLOTS\n",
    "# ==========================================\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 12,\n",
    "    \"axes.labelsize\": 13,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"legend.fontsize\": 11,\n",
    "    \"figure.figsize\": (8, 5)\n",
    "})\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1️⃣ Number of Untruthful Users\n",
    "# ------------------------------------------\n",
    "plt.figure()\n",
    "plt.plot(range(T), danger_counts, marker=\"o\")\n",
    "plt.xlabel(\"Time Interval\")\n",
    "plt.ylabel(\"Number of Untruthful Users\")\n",
    "plt.title(\"Temporal Evolution of Untruthful Users\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"untruthful_users_over_time.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2️⃣ Clustering Metrics\n",
    "# ------------------------------------------\n",
    "plt.figure()\n",
    "plt.plot(range(T), assortativities, marker=\"o\", label=\"Assortativity\")\n",
    "plt.plot(range(T), d2d_ratios, marker=\"s\", label=\"Fraction of Edges Between Untruthful Users\")\n",
    "plt.xlabel(\"Time Interval\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"Structural Concentration of Untruthful Users\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"clustering_metrics_over_time.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3️⃣ Risk Ratio\n",
    "# ------------------------------------------\n",
    "plt.figure()\n",
    "plt.plot(risk_times, risk_ratios, marker=\"o\")\n",
    "plt.axhline(y=1.0, linestyle=\"--\")  # baseline\n",
    "plt.xlabel(\"Transition (t → t+1)\")\n",
    "plt.ylabel(\"Risk Ratio\")\n",
    "plt.title(\"Exposure-Based Risk Ratio Over Time\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"risk_ratio_over_time.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"Improved plots saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99a7fd3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'best_macro_f1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'best_macro_f1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Plot 1 — Macro F1 per Trial\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------\u001b[39;00m\n\u001b[32m     14\u001b[39m plt.figure()\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m plt.bar(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(results_df)), \u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest_macro_f1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     16\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mTrial\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m plt.ylabel(\u001b[33m\"\u001b[39m\u001b[33mBest Macro F1\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johan\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'best_macro_f1'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 7) VISUALIZATIONS\n",
    "# ======================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Reload results (optional safety)\n",
    "results_df = pd.read_csv(\"full_sweep_results.csv\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Plot 1 — Macro F1 per Trial\n",
    "# ------------------------------------------------------\n",
    "plt.figure()\n",
    "plt.bar(range(len(results_df)), results_df[\"best_macro_f1\"])\n",
    "plt.xlabel(\"Trial\")\n",
    "plt.ylabel(\"Best Macro F1\")\n",
    "plt.title(\"Macro F1 per Trial\")\n",
    "plt.xticks(range(len(results_df)))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_macro_f1_per_trial.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Plot 2 — Macro F1 by Threshold\n",
    "# ------------------------------------------------------\n",
    "plt.figure()\n",
    "\n",
    "thresholds = sorted(results_df[\"threshold\"].unique())\n",
    "means = []\n",
    "\n",
    "for th in thresholds:\n",
    "    subset = results_df[results_df[\"threshold\"] == th]\n",
    "    means.append(subset[\"best_macro_f1\"].mean())\n",
    "\n",
    "plt.plot(thresholds, means)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Average Macro F1\")\n",
    "plt.title(\"Average Macro F1 vs Threshold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_macro_f1_by_threshold.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Plot 3 — Class-wise F1 for Best Trial\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Identify best config\n",
    "best_row = results_df.iloc[0]\n",
    "\n",
    "print(\"Best row for plotting:\", best_row)\n",
    "\n",
    "# Re-load best model metrics from last validation run\n",
    "# (Assumes you printed per-class F1 for the best trial)\n",
    "\n",
    "# If you want exact per-class F1 stored,\n",
    "# you should also store them during sweep.\n",
    "# For now, we assume you manually note them.\n",
    "\n",
    "# Example placeholders (replace if you store actual values)\n",
    "f1_class_1 = best_trial_macro  # Replace properly if saved\n",
    "f1_class_0 = best_trial_macro  # Replace properly if saved\n",
    "\n",
    "plt.figure()\n",
    "plt.bar([\"Class 0\", \"Class 1\"], [f1_class_0, f1_class_1])\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"Class-wise F1 (Best Model)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_classwise_f1_best.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Plots saved:\")\n",
    "print(\"- plot_macro_f1_per_trial.png\")\n",
    "print(\"- plot_macro_f1_by_threshold.png\")\n",
    "print(\"- plot_classwise_f1_best.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1382eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# TEMPORAL TRAIN / TEST + F1 SCORE\n",
    "# ================================\n",
    "\n",
    "import torch\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1) Determine comment feature dimensionality\n",
    "# -------------------------------------------------------\n",
    "any_user = next(\n",
    "    u for u in temporal_graph.user_nodes.values()\n",
    "    if len(u.comments) > 0\n",
    ")\n",
    "any_comment = next(iter(any_user.comments.values()))\n",
    "COMMENT_DIM = any_comment.feature_vec.shape[0]\n",
    "print(\"COMMENT_DIM =\", COMMENT_DIM)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2) Device\n",
    "# -------------------------------------------------------\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3) Temporal split (by time interval)\n",
    "# -------------------------------------------------------\n",
    "T = len(temporal_graph.time_intervall.time_intervalls)\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "T_TRAIN = int(T * TRAIN_RATIO)\n",
    "\n",
    "train_timesteps = list(range(0, T_TRAIN))\n",
    "test_timesteps  = list(range(T_TRAIN, T))\n",
    "\n",
    "print(f\"Train timesteps: 0 → {T_TRAIN-1}\")\n",
    "print(f\"Test timesteps:  {T_TRAIN} → {T-1}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4) Initialize model\n",
    "# -------------------------------------------------------\n",
    "print(\"Initializing model with use_past_y = True\")\n",
    "model = TemporalTruthModel(\n",
    "    COMMENT_DIM,\n",
    "    use_past_y=True\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5) Helper: accuracy + F1\n",
    "# -------------------------------------------------------\n",
    "def compute_metrics(logits, labels, threshold=0.5):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = (probs > threshold).float()\n",
    "\n",
    "    tp = ((preds == 1) & (labels == 1)).sum().item()\n",
    "    fp = ((preds == 1) & (labels == 0)).sum().item()\n",
    "    fn = ((preds == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall    = tp / (tp + fn + 1e-8)\n",
    "    f1        = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\n",
    "    acc = (preds == labels).float().mean().item()\n",
    "\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6) Training loop (TRAIN ONLY on early timesteps)\n",
    "# -------------------------------------------------------\n",
    "EPOCHS = 20\n",
    "print(\"\\nStarting training for\", EPOCHS, \"epochs...\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits_all, labels_all = model(temporal_graph)\n",
    "\n",
    "    # ---- TRAIN LOSS (only train timesteps) ----\n",
    "    train_loss = sum(\n",
    "        criterion(logits_all[t], labels_all[t])\n",
    "        for t in train_timesteps\n",
    "    )\n",
    "\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # ---- TRAIN METRICS ----\n",
    "    with torch.no_grad():\n",
    "        train_logits = torch.cat([logits_all[t] for t in train_timesteps])\n",
    "        train_labels = torch.cat([labels_all[t] for t in train_timesteps])\n",
    "        acc, p, r, f1 = compute_metrics(train_logits, train_labels)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train loss: {train_loss.item():.4f} | \"\n",
    "        f\"Acc: {acc:.3f} | \"\n",
    "        f\"F1: {f1:.3f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 7) Evaluation on TEST timesteps\n",
    "# -------------------------------------------------------\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_all, labels_all = model(temporal_graph)\n",
    "\n",
    "    test_logits = torch.cat([logits_all[t] for t in test_timesteps])\n",
    "    test_labels = torch.cat([labels_all[t] for t in test_timesteps])\n",
    "\n",
    "    acc, p, r, f1 = compute_metrics(test_logits, test_labels)\n",
    "\n",
    "print(\"\\n===== TEST RESULTS =====\")\n",
    "print(f\"Accuracy : {acc:.3f}\")\n",
    "print(f\"Precision: {p:.3f}\")\n",
    "print(f\"Recall   : {r:.3f}\")\n",
    "print(f\"F1 score : {f1:.3f}\")\n",
    "print(\"========================\\n\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 8) Save model\n",
    "# -------------------------------------------------------\n",
    "torch.save(model.state_dict(), \"temporal_truth_model.pt\")\n",
    "print(\"Model saved to temporal_truth_model.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331878bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph.comment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186892c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = temporal_graph.TemporalGraph()\n",
    "graph.clean_nodes(True, True, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b32c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "dangerous_users=[6609,211,4273,8242,1772,6559,9365,3321,4248,8759,455,9264,4869,4210,8760,5807,805,8751,8256,6157]\n",
    "for dangerous_user in dangerous_users:\n",
    "    print(graph.nodes_dict[str(dangerous_user)].username)\n",
    "# value = random.choice(list(graph.nodes_dict.values()))\n",
    "\n",
    "value = graph.nodes_dict[\"6609\"]\n",
    "value.node_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.find_truth(\"807621\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb775e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for truth_id in graph.nodes_dict[\"20054\"].truths:\n",
    "    print(type(truth_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39df5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.create_pyvis_representation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b794f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m zero_counter_follower = \u001b[32m0\u001b[39m\n\u001b[32m     11\u001b[39m zero_counter_message = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgraph\u001b[49m.nodes_dict.keys():\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(graph.nodes_dict[key].following_edges) != \u001b[32m0\u001b[39m:\n\u001b[32m     15\u001b[39m         following_edges_per_node.append(\u001b[38;5;28mlen\u001b[39m(graph.nodes_dict[key].following_edges))\n",
      "\u001b[31mNameError\u001b[39m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "following_edges_per_node = []\n",
    "follower_edges_per_node = []\n",
    "messages_per_node = []\n",
    "\n",
    "counter_follower = 0\n",
    "counter_following = 0\n",
    "counter_message = 0\n",
    "\n",
    "zero_counter_following = 0\n",
    "zero_counter_follower = 0\n",
    "zero_counter_message = 0\n",
    "\n",
    "for key in graph.nodes_dict.keys():\n",
    "    if len(graph.nodes_dict[key].following_edges) != 0:\n",
    "        following_edges_per_node.append(len(graph.nodes_dict[key].following_edges))\n",
    "        counter_following += 1\n",
    "    else:\n",
    "        zero_counter_following += 1\n",
    "\n",
    "    if len(graph.nodes_dict[key].truths) != 0:\n",
    "        messages_per_node.append(len(graph.nodes_dict[key].truths))\n",
    "        counter_message += 1\n",
    "    else:\n",
    "        zero_counter_message += 1\n",
    "\n",
    "    if len(graph.nodes_dict[key].follower_edges) != 0:\n",
    "        follower_edges_per_node.append(len(graph.nodes_dict[key].follower_edges))\n",
    "        counter_follower += 1\n",
    "    else:\n",
    "        zero_counter_follower += 1\n",
    "\n",
    "print(f\"nodes with no known followings: {zero_counter_following} nodes with followings:{counter_following}\")\n",
    "print(f\"nodes with no known messages: {zero_counter_message} with known messages:{counter_message}\")\n",
    "print(f\"nodes with no known followers: {zero_counter_follower} nodes with followers:{counter_follower}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d03ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.median(following_edges_per_node))\n",
    "plt.hist(following_edges_per_node, bins=3000)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(follower_edges_per_node, bins=3000)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(messages_per_node, bins=3000)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "johan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
